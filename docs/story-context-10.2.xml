<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>10</epicId>
    <storyId>2</storyId>
    <title>Performance Testing and Optimization</title>
    <status>Approved</status>
    <generatedAt>2025-10-27</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>/home/snapiz/projects/github/timayz/imkitchen/docs/stories/story-10.2.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>performance engineer</asA>
    <iWant>validate system performance benchmarks through comprehensive load testing</iWant>
    <soThat>the enhanced meal planning system meets performance targets under realistic concurrent load before production deployment</soThat>
    <tasks>
      - Setup k6 load testing infrastructure
      - Implement load test scenarios (generation, navigation, regeneration, shopping)
      - Database query profiling (N+1 query detection, index usage)
      - Memory profiling (heap analysis, leak detection)
      - Performance regression testing in CI
      - Optimization (if benchmarks not met)
    </tasks>
  </story>

  <acceptanceCriteria>
    1. Load test with 100 concurrent multi-week generation requests
    2. P95 generation time &lt;5 seconds
    3. P95 route response time &lt;500ms
    4. Database query performance profiled (no N+1 queries)
    5. Memory usage profiled (no leaks, bounded growth)
    6. Performance regression tests added to CI
    7. Optimization recommendations documented (if targets not met)
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>/home/snapiz/projects/github/timayz/imkitchen/docs/tech-spec-epic-10.md</path>
        <title>Technical Specification: Story 10.2</title>
        <section>Story 10.2: Performance Testing and Optimization (lines 726-758)</section>
        <snippet>Authoritative acceptance criteria, k6 load testing configuration, P95 benchmarks, profiling requirements</snippet>
      </doc>
      <doc>
        <path>/home/snapiz/projects/github/timayz/imkitchen/docs/tech-spec-epic-10.md</path>
        <title>Performance Requirements</title>
        <section>Non-Functional Requirements - Performance (lines 521-542)</section>
        <snippet>Performance benchmarks table: P95 generation &lt;5s, routes &lt;500ms, error rate &lt;1%, memory growth bounds</snippet>
      </doc>
      <doc>
        <path>/home/snapiz/projects/github/timayz/imkitchen/docs/tech-spec-epic-10.md</path>
        <title>Database Performance Constraints</title>
        <section>Database Performance Constraints (lines 106-115)</section>
        <snippet>Connection pool configuration, WAL mode, PRAGMA optimizations (journal_mode, cache_size, synchronous)</snippet>
      </doc>
      <doc>
        <path>/home/snapiz/projects/github/timayz/imkitchen/docs/tech-spec-epic-10.md</path>
        <title>Workflow 2: Performance Testing Flow</title>
        <section>Workflow 2: Performance Testing Flow (lines 430-473)</section>
        <snippet>k6 script configuration, virtual users (100), test stages, metrics collection (OpenTelemetry), profiling analysis</snippet>
      </doc>
      <doc>
        <path>/home/snapiz/projects/github/timayz/imkitchen/docs/epics.md</path>
        <title>Epic 10, Story 10.2</title>
        <section>Epic 10, Story 10.2 (lines 2315-2336)</section>
        <snippet>User story statement, prerequisites (Epic 7, 8 complete), technical notes (k6, realistic data)</snippet>
      </doc>
      <doc>
        <path>/home/snapiz/projects/github/timayz/imkitchen/docs/PRD.md</path>
        <title>PRD Performance Requirements</title>
        <section>NFR-1, NFR-4</section>
        <snippet>Generation &lt;5s P95, Routes &lt;500ms P95, 100 concurrent users, scalability to 10K users</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>e2e/performance/load-test.js</path>
        <kind>performance-test</kind>
        <symbol>k6 load test script</symbol>
        <lines>N/A (to be created)</lines>
        <reason>100 virtual users, 5-minute sustained load, test scenarios for generation/navigation/regeneration/shopping</reason>
      </artifact>
      <artifact>
        <path>e2e/performance/baseline.json</path>
        <kind>config</kind>
        <symbol>Baseline P95 latencies</symbol>
        <lines>N/A (to be created)</lines>
        <reason>Performance regression detection: compare current vs baseline, fail if &gt;20% slower</reason>
      </artifact>
      <artifact>
        <path>crates/meal_planning/src/algorithm.rs</path>
        <kind>domain-logic</kind>
        <symbol>generate_multi_week</symbol>
        <lines>N/A</lines>
        <reason>Multi-week generation algorithm (primary performance bottleneck to profile)</reason>
      </artifact>
      <artifact>
        <path>src/database/connection_pool.rs</path>
        <kind>infrastructure</kind>
        <symbol>SQLite connection pool</symbol>
        <lines>N/A</lines>
        <reason>Write pool (1 connection), Read pool (5 connections), WAL mode configuration</reason>
      </artifact>
    </code>
    <dependencies>
      <rust>
        <package name="sqlx" version="0.8" features="runtime-tokio, sqlite">SQLite database with WAL mode, query logging</package>
        <package name="opentelemetry" version="0.31">Distributed tracing for latency analysis</package>
        <package name="opentelemetry-otlp" version="0.31" features="trace, grpc-tonic">Metrics export</package>
      </rust>
      <tools>
        <tool name="k6" version="0.50+">Load testing tool (100 virtual users, 5-minute sustained load)</tool>
        <tool name="cargo-flamegraph" version="0.6+">Heap profiling for memory analysis</tool>
        <tool name="valgrind" version="3.21+">Memory leak detection (C dependencies)</tool>
        <tool name="sqlite3" version="3.45+">Database query profiling (EXPLAIN QUERY PLAN)</tool>
      </tools>
    </dependencies>
  </artifacts>

  <constraints>
    - k6 load test: 100 concurrent virtual users (represents 20% of peak load for 10K MAU)
    - Test duration: 5 minutes sustained load with 30-second ramp-up
    - Test data: Realistic dataset (50 favorite recipes per user)
    - P95 benchmarks: Generation &lt;5s, Routes &lt;500ms (NFR requirements from PRD)
    - SQLite WAL mode required for concurrent reads/writes during load testing
    - Connection pool: Write pool (1 connection), Read pool (5 connections)
    - No N+1 queries allowed (SQLx query log analysis required)
    - Memory growth must be bounded (&lt;100MB per 1000 requests)
    - Performance regression tests: warn if &gt;10% slower, fail if &gt;20% slower
    - Profile with release build (not debug for accurate performance results)
  </constraints>

  <interfaces>
    <interface>
      <name>POST /plan/generate-multi-week</name>
      <kind>HTTP route</kind>
      <signature>Form { num_weeks: u32 } -&gt; 303 Redirect</signature>
      <path>src/routes/meal_planning</path>
      <performance>P95 &lt;5s (NFR requirement)</performance>
    </interface>
    <interface>
      <name>GET /plan?week=YYYY-MM-DD</name>
      <kind>HTTP route</kind>
      <signature>Query { week: Option&lt;String&gt; } -&gt; 200 HTML</signature>
      <path>src/routes/meal_planning</path>
      <performance>P95 &lt;500ms</performance>
    </interface>
    <interface>
      <name>POST /plan/regenerate-week</name>
      <kind>HTTP route</kind>
      <signature>Query { week: String } -&gt; 303 Redirect</signature>
      <path>src/routes/meal_planning</path>
      <performance>P95 &lt;3s (single week faster than multi-week)</performance>
    </interface>
    <interface>
      <name>GET /shopping?week=YYYY-MM-DD</name>
      <kind>HTTP route</kind>
      <signature>Query { week: Option&lt;String&gt; } -&gt; 200 HTML</signature>
      <path>src/routes/shopping</path>
      <performance>P95 &lt;500ms</performance>
    </interface>
  </interfaces>

  <tests>
    <standards>
      k6 load testing with 100 concurrent virtual users. Sustained 5-minute load with 30-second ramp-up. Thresholds: P95 generation &lt;5s, routes &lt;500ms, error rate &lt;1%. SQLx query logging enabled (RUST_LOG=sqlx=debug). Heap profiling via cargo-flamegraph. Memory leak detection via valgrind. Performance regression tests in CI (manual trigger). Baseline metrics versioned in Git (e2e/performance/baseline.json).
    </standards>
    <locations>
      e2e/performance/load-test.js (k6 script)
      e2e/performance/baseline.json (baseline P95 latencies)
      .github/workflows/performance.yml (CI workflow)
    </locations>
    <ideas>
      <idea ac="1">Test: Configure k6 with 100 virtual users, 5-minute sustained load, 30-second ramp-up</idea>
      <idea ac="1">Test: Seed test data (100 users, 50 recipes each) before load test</idea>
      <idea ac="2">Test: Run load test for POST /plan/generate-multi-week, verify P95 &lt;5000ms</idea>
      <idea ac="3">Test: Run load test for GET /plan?week, verify P95 &lt;500ms</idea>
      <idea ac="3">Test: Run load test for GET /shopping?week, verify P95 &lt;500ms</idea>
      <idea ac="4">Test: Enable SQLx query logging, analyze for N+1 patterns (ingredient loading, recipe fetching)</idea>
      <idea ac="4">Test: Run EXPLAIN QUERY PLAN for all meal planning queries, verify index usage</idea>
      <idea ac="5">Test: Generate heap profile via cargo-flamegraph during load test</idea>
      <idea ac="5">Test: Verify memory growth &lt;100MB per 1000 requests (linear, bounded)</idea>
      <idea ac="6">Test: Create baseline.json with P95 latencies from successful load test</idea>
      <idea ac="6">Test: Implement comparison script (current vs baseline), fail if &gt;20% slower</idea>
      <idea ac="7">Test: If benchmarks fail, document bottlenecks in docs/performance-report.md</idea>
    </ideas>
  </tests>
</story-context>
